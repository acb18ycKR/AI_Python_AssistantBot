{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402bf426",
   "metadata": {},
   "source": [
    "## 설치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627f403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain umap-learn scikit-learn langchain_community tiktoken langchain-openai langchainhub chromadb langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7554354",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\n",
    "\n",
    "[RAPTOR](https://arxiv.org/pdf/2401.18059.pdf) 논문은 문서의 색인 생성 및 검색에 대한 흥미로운 접근 방식을 제시합니다.\n",
    "\n",
    "[테디노트 논문 요약글(노션)](https://teddylee777.notion.site/RAPTOR-e835d306fc664dc2ad76191dee1cd859?pvs=4)\n",
    "\n",
    "- `leafs`는 시작 문서 집합입니다.\n",
    "- leafs는 임베딩되어 클러스터링됩니다.\n",
    "- 그런 다음 클러스터는 유사한 문서들 간의 정보를 더 높은 수준(더 추상적인)으로 요약합니다.\n",
    "\n",
    "이 과정은 재귀적으로 수행되어, 원본 문서(`leafs`)에서 더 추상적인 요약으로 이어지는 \"트리\"를 형성합니다.\n",
    "\n",
    "이를 다양한 규모에서 적용할 수 있습니다; `leafs`는 다음과 같을 수 있습니다:\n",
    "\n",
    "- 단일 문서에서의 텍스트 청크(논문에서 보여준 것처럼)\n",
    "- 전체 문서(아래에서 보여주는 것처럼)\n",
    "\n",
    "더 긴 컨텍스트의 LLMs를 사용하면, 전체 문서에 대해 이 작업을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c9f09",
   "metadata": {},
   "source": [
    "### 문서\n",
    "\n",
    "LangChain의 LCEL 문서에 이를 적용해 봅시다.\n",
    "\n",
    "이 경우, 각 `doc`은 LCEL 문서의 고유한 웹 페이지입니다.\n",
    "\n",
    "콘텍스트는 2,000 토큰 미만에서 10,000 토큰 이상까지 다양합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba7426",
   "metadata": {},
   "source": [
    "웹 문서에서 텍스트 데이터를 추출하고, 텍스트의 토큰 수를 계산하여 히스토그램으로 시각화하는 과정을 설명합니다.\n",
    "\n",
    "- `tiktoken` 라이브러리를 사용하여 주어진 인코딩 이름에 따라 문자열의 토큰 수를 계산합니다.\n",
    "- `RecursiveUrlLoader` 클래스를 사용하여 지정된 URL에서 웹 문서를 재귀적으로 로드합니다. 이 과정에서 `BeautifulSoup`를 활용하여 HTML 문서에서 텍스트를 추출합니다.\n",
    "- 여러 URL에서 문서를 로드하여 모든 텍스트 데이터를 하나의 리스트에 모읍니다.\n",
    "- 각 문서 텍스트에 대해 `num_tokens_from_string` 함수를 호출하여 토큰 수를 계산하고, 이를 리스트에 저장합니다.\n",
    "- `matplotlib`를 사용하여 계산된 토큰 수의 분포를 히스토그램으로 시각화합니다. 히스토그램은 토큰 수를 x축에, 해당 토큰 수를 가진 문서의 빈도수를 y축에 나타냅니다.\n",
    "- 히스토그램은 데이터의 분포를 이해하는 데 도움을 주며, 특히 텍스트 데이터의 길이 분포를 시각적으로 파악할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584b6dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Matplotlib installed and imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3506db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    # 주어진 문자열에서 토큰의 개수를 반환합니다.\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "# LCEL 문서 로드\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# PydanticOutputParser를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# Self Query를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "# 문서 텍스트\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "docs_texts = [d.page_content for d in docs]\n",
    "\n",
    "# 각 문서에 대한 토큰 수 계산\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]\n",
    "\n",
    "# 토큰 수의 히스토그램을 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Token Counts in LCEL Documents\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# 히스토그램을 표시합니다.\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9d8ad",
   "metadata": {},
   "source": [
    "문서 텍스트를 정렬하고 연결하여 토큰 수를 계산하는 과정을 설명합니다.\n",
    "\n",
    "- 문서(`docs`)를 메타데이터의 \"source\" 키를 기준으로 정렬합니다.\n",
    "- 정렬된 문서 리스트를 역순으로 뒤집습니다.\n",
    "- 역순으로 된 문서의 내용을 특정 구분자(`\"\\n\\n\\n --- \\n\\n\\n\"`)를 사용하여 연결합니다.\n",
    "- 연결된 내용의 토큰 수를 `num_tokens_from_string` 함수를 사용하여 계산하고, 이를 출력합니다. 이때, `\"cl100k_base\"` 모델을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0a783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 3585\n"
     ]
    }
   ],
   "source": [
    "# 문서 텍스트를 연결합니다.\n",
    "# 문서를 출처 메타데이터 기준으로 정렬합니다.\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))  # 정렬된 문서를 역순으로 배열합니다.\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [\n",
    "        # 역순으로 배열된 문서의 내용을 연결합니다.\n",
    "        doc.page_content\n",
    "        for doc in d_reversed\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Num tokens in all context: %s\"  # 모든 문맥에서의 토큰 수를 출력합니다.\n",
    "    % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a33263",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter`를 사용하여 텍스트를 분할하는 과정을 설명합니다.\n",
    "\n",
    "- `chunk_size_tok` 변수를 설정하여, 각 텍스트 청크의 크기를 2000 토큰으로 지정합니다.\n",
    "- `RecursiveCharacterTextSplitter`의 `from_tiktoken_encoder` 메소드를 사용하여 텍스트 분할기를 초기화합니다. 여기서 청크 크기(`chunk_size`)와 청크 간 겹침(`chunk_overlap`)을 0으로 설정합니다.\n",
    "- 초기화된 텍스트 분할기의 `split_text` 메소드를 호출하여, `concatenated_content`라는 변수에 저장된 연결된 텍스트를 분할합니다. 분할 결과는 `texts_split` 변수에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8982e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할을 위한 코드\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 2000  # 토큰의 청크 크기를 설정합니다.\n",
    "# 재귀적 문자 텍스트 분할기를 초기화합니다. 토큰 인코더를 사용하여 청크 크기와 중복을 설정합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size_tok, chunk_overlap=0\n",
    ")\n",
    "texts_split = text_splitter.split_text(\n",
    "    concatenated_content\n",
    ")  # 주어진 텍스트를 분할합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1758e3",
   "metadata": {},
   "source": [
    "## 모델\n",
    "\n",
    "다양한 모델을 테스트할 수 있으며, 새로운 [Claude3](https://www.anthropic.com/news/claude-3-family) 계열도 포함됩니다.\n",
    "\n",
    "관련 API 키를 설정하는 것을 잊지 마세요.\n",
    "\n",
    "- `OPENAI_API_KEY`, Anthropic 을 사용하는 경우 `ANTHROPIC_API_KEY`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e1803",
   "metadata": {},
   "source": [
    "`ChatOpenAI` 혹은 `ChatAnthropic` + `OpenAIEmbeddings`를 사용하여 챗봇 모델을 구현합니다.\n",
    "\n",
    "- `OpenAIEmbeddings`를 인스턴스화하여 OpenAI의 임베딩 기능을 초기화합니다.\n",
    "- `ChatOpenAI` 혹은 `ChatAnthropic` 을 사용하여 `temperature`를 0으로 설정하고, 챗봇 모델을 초기화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1a8129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0990c",
   "metadata": {},
   "source": [
    "Cache Embedding 을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d18ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# embeddings 인스턴스를 생성합니다.\n",
    "embd = OpenAIEmbeddings(model=\"text-embedding-3-small\", disallowed_special=())\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embd, store, namespace=embd.model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc61f6",
   "metadata": {},
   "source": [
    "모델을 초기화 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48631ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다. 모델은 \"gpt-4-turbo-preview\"를 사용합니다.\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# ChatAnthropic 모델을 초기화합니다. 온도는 0으로 설정하고, 모델은 \"claude-3-opus-20240229\"를 사용합니다.\n",
    "# model = ChatAnthropic(temperature=0, model=\"claude-3-opus-20240229\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89741a7",
   "metadata": {},
   "source": [
    "### 트리 구축\n",
    "\n",
    "트리 구축에서의 클러스터링 접근 방식에는 몇 가지 흥미로운 아이디어가 포함되어 있습니다.\n",
    "\n",
    "**GMM (가우시안 혼합 모델)**\n",
    "\n",
    "- 다양한 클러스터에 걸쳐 데이터 포인트의 분포를 모델링합니다.\n",
    "- 모델의 베이지안 정보 기준(BIC)을 평가하여 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "**UMAP (Uniform Manifold Approximation and Projection)**\n",
    "\n",
    "- 클러스터링을 지원합니다.\n",
    "- 고차원 데이터의 차원을 축소합니다.\n",
    "- UMAP은 데이터 포인트의 유사성에 기반하여 자연스러운 그룹화를 강조하는 데 도움을 줍니다.\n",
    "\n",
    "**지역 및 전역 클러스터링**\n",
    "\n",
    "- 다양한 규모에서 데이터를 분석하는 데 사용됩니다.\n",
    "- 데이터 내의 세밀한 패턴과 더 넓은 패턴 모두를 효과적으로 포착합니다.\n",
    "\n",
    "**임계값 설정**\n",
    "\n",
    "- GMM의 맥락에서 클러스터 멤버십을 결정하기 위해 적용됩니다.\n",
    "- 확률 분포를 기반으로 합니다(데이터 포인트를 ≥ 1 클러스터에 할당).\n",
    "\n",
    "---\n",
    "\n",
    "GMM 및 임계값 설정에 대한 코드는 아래 두 출처에서 언급된 Sarthi et al의 것입니다:\n",
    "\n",
    "- [원본 저장소](https://github.com/parthsarthi03/raptor/blob/master/raptor/cluster_tree_builder.py)\n",
    "- [소소한 조정](https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py)\n",
    "\n",
    "두 저자 모두에게 전적인 공로를 인정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd012a",
   "metadata": {},
   "source": [
    "`global_cluster_embeddings` 함수는 임베딩의 글로벌 차원 축소를 수행하기 위해 UMAP을 사용합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)을 UMAP을 사용하여 지정된 차원(`dim`)으로 차원 축소합니다.\n",
    "- `n_neighbors`는 각 포인트를 고려할 이웃의 수를 지정하며, 제공되지 않을 경우 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "- `metric`은 UMAP에 사용될 거리 측정 기준을 지정합니다.\n",
    "- 결과로, 지정된 차원으로 축소된 임베딩이 numpy 배열로 반환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2970a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 42  # 재현성을 위한 고정된 시드 값\n",
    "\n",
    "### --- 위의 인용된 코드에서 주석과 문서화를 추가함 --- ###\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAP을 사용하여 임베딩의 전역 차원 축소를 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원.\n",
    "    - n_neighbors: 선택 사항; 각 점을 고려할 이웃의 수.\n",
    "                   제공되지 않으면 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd077834",
   "metadata": {},
   "source": [
    "임베딩 데이터에 대해 지역 차원 축소를 수행하는 함수 `local_cluster_embeddings`를 구현합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)을 UMAP을 사용하여 지정된 차원(`dim`)으로 차원 축소합니다.\n",
    "- 차원 축소 과정에서 각 점에 대해 고려할 이웃의 수(`num_neighbors`)와 거리 측정 메트릭(`metric`)을 파라미터로 사용합니다.\n",
    "- 최종적으로 차원이 축소된 임베딩을 `numpy` 배열로 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d961ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 지역 차원 축소를 수행합니다. 이는 일반적으로 전역 클러스터링 이후에 사용됩니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원 수.\n",
    "    - num_neighbors: 각 점에 대해 고려할 이웃의 수.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30f112",
   "metadata": {},
   "source": [
    "`get_optimal_clusters` 함수는 주어진 임베딩 데이터를 기반으로 최적의 클러스터 수를 결정하는 데 사용됩니다. 이 과정은 가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(Bayesian Information Criterion, BIC)을 계산함으로써 수행됩니다.\n",
    "\n",
    "- 입력 임베딩(`embeddings`)은 numpy 배열로 제공됩니다.\n",
    "- 최대 클러스터 수(`max_clusters`)는 고려할 클러스터의 최대 수를 지정합니다. 기본값은 50입니다.\n",
    "- 재현성을 위한 난수 상태(`random_state`)는 고정된 값을 사용합니다.\n",
    "- 함수는 입력 임베딩에 대해 여러 클러스터 수를 시도하며 각각에 대한 BIC 값을 계산합니다.\n",
    "- 최소 BIC 값을 가지는 클러스터 수를 최적의 클러스터 수로 결정하고 반환합니다.\n",
    "\n",
    "이 함수는 클러스터링 문제에서 데이터를 가장 잘 설명하는 클러스터 수를 자동으로 찾는 데 유용하게 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade041a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(BIC)을 통해 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - max_clusters: 고려할 최대 클러스터 수.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 발견된 최적의 클러스터 수를 나타내는 정수.\n",
    "    \"\"\"\n",
    "    max_clusters = min(\n",
    "        max_clusters, len(embeddings)\n",
    "    )  # 최대 클러스터 수와 임베딩의 길이 중 작은 값을 최대 클러스터 수로 설정\n",
    "    n_clusters = np.arange(1, max_clusters)  # 1부터 최대 클러스터 수까지의 범위를 생성\n",
    "    bics = []  # BIC 점수를 저장할 리스트\n",
    "    for n in n_clusters:  # 각 클러스터 수에 대해 반복\n",
    "        gm = GaussianMixture(\n",
    "            n_components=n, random_state=random_state\n",
    "        )  # 가우시안 혼합 모델 초기화\n",
    "        gm.fit(embeddings)  # 임베딩에 대해 모델 학습\n",
    "        bics.append(gm.bic(embeddings))  # 학습된 모델의 BIC 점수를 리스트에 추가\n",
    "    return n_clusters[np.argmin(bics)]  # BIC 점수가 가장 낮은 클러스터 수를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27119b8",
   "metadata": {},
   "source": [
    "`GMM_cluster` 함수는 임베딩을 가우시안 혼합 모델(Gaussian Mixture Model, GMM)을 사용하여 클러스터링합니다. 이 과정은 확률 임계값을 기반으로 합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)은 numpy 배열로 제공됩니다.\n",
    "- `threshold`는 임베딩을 특정 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "- `random_state`는 결과의 재현성을 위한 시드 값입니다.\n",
    "- 최적의 클러스터 수를 결정하기 위해 `get_optimal_clusters` 함수를 호출합니다.\n",
    "- 결정된 클러스터 수를 바탕으로 가우시안 혼합 모델을 초기화하고, 입력된 임베딩에 대해 학습을 수행합니다.\n",
    "- 각 임베딩에 대한 클러스터 할당 확률을 계산하고, 이 확률이 주어진 임계값을 초과하는 경우 해당 임베딩을 클러스터에 할당합니다.\n",
    "- 함수는 최종적으로 임베딩의 클러스터 레이블과 결정된 클러스터 수를 튜플로 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86a6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    확률 임계값을 기반으로 가우시안 혼합 모델(GMM)을 사용하여 임베딩을 클러스터링합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - threshold: 임베딩을 클러스터에 할당하기 위한 확률 임계값.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 클러스터 레이블과 결정된 클러스터 수를 포함하는 튜플.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 최적의 클러스터 수를 구합니다.\n",
    "    # 가우시안 혼합 모델을 초기화합니다.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)  # 임베딩에 대해 모델을 학습합니다.\n",
    "    probs = gm.predict_proba(\n",
    "        embeddings\n",
    "    )  # 임베딩이 각 클러스터에 속할 확률을 예측합니다.\n",
    "    # 임계값을 초과하는 확률을 가진 클러스터를 레이블로 선택합니다.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters  # 레이블과 클러스터 수를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d9bd6",
   "metadata": {},
   "source": [
    "`perform_clustering` 함수는 임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 글로벌 클러스터링, 그리고 각 글로벌 클러스터 내에서의 로컬 클러스터링을 수행하여 클러스터링 결과를 반환합니다.\n",
    "\n",
    "- 입력된 임베딩(`embeddings`)에 대해 차원 축소를 수행합니다. 이는 UMAP을 사용하여 지정된 차원(`dim`)으로 임베딩의 차원을 축소하는 과정을 포함합니다.\n",
    "- 차원이 축소된 임베딩에 대해 가우시안 혼합 모델(GMM)을 사용하여 글로벌 클러스터링을 수행합니다. 클러스터 할당은 주어진 확률 임계값(`threshold`)을 기준으로 결정됩니다.\n",
    "- 각 글로벌 클러스터 내에서 추가적인 로컬 클러스터링을 수행합니다. 이 과정은 글로벌 클러스터링 결과를 바탕으로 각 글로벌 클러스터에 속한 임베딩들만을 대상으로 다시 차원 축소 및 GMM 클러스터링을 진행합니다.\n",
    "- 최종적으로, 모든 임베딩에 대해 글로벌 및 로컬 클러스터 ID를 할당하여, 각 임베딩이 속한 클러스터 ID를 담은 리스트를 반환합니다. 이 리스트는 임베딩의 순서에 따라 각 임베딩에 대한 클러스터 ID 배열을 포함합니다.\n",
    "\n",
    "이 함수는 고차원 데이터의 클러스터링을 위해 글로벌 및 로컬 차원에서의 클러스터링을 결합한 접근 방식을 제공합니다. 이를 통해 더 세분화된 클러스터링 결과를 얻을 수 있으며, 복잡한 데이터 구조를 보다 효과적으로 분석할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32e97d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 클러스터링, 각 글로벌 클러스터 내에서의 로컬 클러스터링을 순서대로 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩입니다.\n",
    "    - dim: UMAP 축소를 위한 목표 차원입니다.\n",
    "    - threshold: GMM에서 임베딩을 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 각 임베딩의 클러스터 ID를 포함하는 numpy 배열의 리스트입니다.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # 데이터가 충분하지 않을 때 클러스터링을 피합니다.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # 글로벌 차원 축소\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # 글로벌 클러스터링\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # 각 글로벌 클러스터를 순회하며 로컬 클러스터링 수행\n",
    "    for i in range(n_global_clusters):\n",
    "        # 현재 글로벌 클러스터에 속하는 임베딩 추출\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # 작은 클러스터는 직접 할당으로 처리\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 로컬 차원 축소 및 클러스터링\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # 로컬 클러스터 ID 할당, 이미 처리된 총 클러스터 수를 조정\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051d771",
   "metadata": {},
   "source": [
    "텍스트 문서의 목록에 대한 임베딩을 생성하는 함수 `embed`를 구현합니다.\n",
    "\n",
    "- 입력으로 텍스트 문서의 목록(`texts`)을 받습니다.\n",
    "- `embd` 객체의 `embed_documents` 메소드를 사용하여 텍스트 문서의 임베딩을 생성합니다.\n",
    "- 생성된 임베딩을 `numpy.ndarray` 형태로 변환하여 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175963c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # 텍스트 문서 목록에 대한 임베딩을 생성합니다.\n",
    "    #\n",
    "    # 이 함수는 `embd` 객체가 존재한다고 가정하며, 이 객체는 텍스트 목록을 받아 그 임베딩을 반환하는 `embed_documents` 메소드를 가지고 있습니다.\n",
    "    #\n",
    "    # 매개변수:\n",
    "    # - texts: List[str], 임베딩할 텍스트 문서의 목록입니다.\n",
    "    #\n",
    "    # 반환값:\n",
    "    # - numpy.ndarray: 주어진 텍스트 문서들에 대한 임베딩 배열입니다.\n",
    "    text_embeddings = embd.embed_documents(\n",
    "        texts\n",
    "    )  # 텍스트 문서들의 임베딩을 생성합니다.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # 임베딩을 numpy 배열로 변환합니다.\n",
    "    return text_embeddings_np  # 임베딩된 numpy 배열을 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b6b30",
   "metadata": {},
   "source": [
    "`embed_cluster_texts` 함수는 텍스트 목록을 임베딩하고 클러스터링하여, 원본 텍스트, 해당 임베딩, 그리고 할당된 클러스터 라벨을 포함하는 `pandas.DataFrame`을 반환합니다.\n",
    "\n",
    "- 주어진 텍스트 목록에 대해 임베딩을 생성합니다.\n",
    "- 생성된 임베딩을 기반으로 클러스터링을 수행합니다. 이 과정은 사전에 정의된 `perform_clustering` 함수를 사용합니다.\n",
    "- 결과를 저장하기 위해 `pandas.DataFrame`을 초기화합니다.\n",
    "- DataFrame에 원본 텍스트, 임베딩 리스트, 클러스터 라벨을 각각 저장합니다.\n",
    "\n",
    "이 함수는 텍스트 데이터의 임베딩 생성과 클러스터링을 하나의 단계로 결합하여, 텍스트 데이터의 구조적 분석과 그룹화를 용이하게 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "351f42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    텍스트 목록을 임베딩하고 클러스터링하여, 텍스트, 그들의 임베딩, 그리고 클러스터 라벨이 포함된 DataFrame을 반환합니다.\n",
    "\n",
    "    이 함수는 임베딩 생성과 클러스터링을 단일 단계로 결합합니다. 임베딩에 대해 클러스터링을 수행하는 `perform_clustering` 함수의 사전 정의된 존재를 가정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리될 텍스트 문서의 목록입니다.\n",
    "\n",
    "    반환값:\n",
    "    - pandas.DataFrame: 원본 텍스트, 그들의 임베딩, 그리고 할당된 클러스터 라벨이 포함된 DataFrame입니다.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # 임베딩 생성\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # 임베딩에 대해 클러스터링 수행\n",
    "    df = pd.DataFrame()  # 결과를 저장할 DataFrame 초기화\n",
    "    df[\"text\"] = texts  # 원본 텍스트 저장\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # DataFrame에 리스트로 임베딩 저장\n",
    "    df[\"cluster\"] = cluster_labels  # 클러스터 라벨 저장\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a3ecd",
   "metadata": {},
   "source": [
    "`fmt_txt` 함수는 `pandas`의 `DataFrame`에서 텍스트 문서를 단일 문자열로 포맷팅합니다.\n",
    "\n",
    "- 입력 파라미터로 `DataFrame`을 받으며, 이 `DataFrame`은 포맷팅할 텍스트 문서를 포함한 'text' 컬럼을 가져야 합니다.\n",
    "- 모든 텍스트 문서는 특정 구분자(\"--- --- \\n --- ---\")를 사용하여 연결되어 단일 문자열로 반환됩니다.\n",
    "- 함수는 연결된 텍스트 문서를 포함하는 단일 문자열을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrame에 있는 텍스트 문서를 단일 문자열로 포맷합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - df: 'text' 열에 포맷할 텍스트 문서가 포함된 DataFrame.\n",
    "\n",
    "    반환값:\n",
    "    - 모든 텍스트 문서가 특정 구분자로 결합된 단일 문자열.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()  # 'text' 열의 모든 텍스트를 리스트로 변환\n",
    "    return \"--- --- \\n --- --- \".join(\n",
    "        unique_txt\n",
    "    )  # 텍스트 문서들을 특정 구분자로 결합하여 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc49b18",
   "metadata": {},
   "source": [
    "텍스트 데이터를 임베딩하고, 클러스터링하며, 각 클러스터에 대한 요약을 생성하는 과정을 수행합니다.\n",
    "\n",
    "- 주어진 텍스트 목록에 대해 임베딩을 생성하고 유사성에 기반한 클러스터링을 진행합니다. 이 과정은 `df_clusters` 데이터프레임을 결과로 합니다. 이 데이터프레임에는 원본 텍스트, 임베딩, 그리고 클러스터 할당 정보가 포함됩니다.\n",
    "- 클러스터 할당을 쉽게 처리하기 위해 데이터프레임 항목을 확장합니다. 각 행은 텍스트, 임베딩, 클러스터를 포함하는 새로운 데이터프레임으로 변환됩니다.\n",
    "- 확장된 데이터프레임에서 고유한 클러스터 식별자를 추출하고, 각 클러스터에 대한 텍스트를 포맷팅하여 요약을 생성합니다. 이 요약은 `df_summary` 데이터프레임에 저장됩니다. 이 데이터프레임은 각 클러스터의 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "- 최종적으로, 함수는 두 개의 데이터프레임을 포함하는 튜플을 반환합니다. 첫 번째 데이터프레임은 원본 텍스트, 임베딩, 클러스터 할당 정보를 포함하며, 두 번째 데이터프레임은 각 클러스터에 대한 요약과 해당 세부 수준, 클러스터 식별자를 포함합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c242240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    텍스트 목록에 대해 임베딩, 클러스터링 및 요약을 수행합니다. 이 함수는 먼저 텍스트에 대한 임베딩을 생성하고,\n",
    "    유사성을 기반으로 클러스터링을 수행한 다음, 클러스터 할당을 확장하여 처리를 용이하게 하고 각 클러스터 내의 내용을 요약합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: 처리할 텍스트 문서 목록입니다.\n",
    "    - level: 처리의 깊이나 세부 사항을 정의할 수 있는 정수 매개변수입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 두 개의 데이터프레임을 포함하는 튜플:\n",
    "      1. 첫 번째 데이터프레임(`df_clusters`)은 원본 텍스트, 그들의 임베딩, 그리고 클러스터 할당을 포함합니다.\n",
    "      2. 두 번째 데이터프레임(`df_summary`)은 각 클러스터에 대한 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 텍스트를 임베딩하고 클러스터링하여 'text', 'embd', 'cluster' 열이 있는 데이터프레임을 생성합니다.\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # 클러스터를 쉽게 조작하기 위해 데이터프레임을 확장할 준비를 합니다.\n",
    "    expanded_list = []\n",
    "\n",
    "    # 데이터프레임 항목을 문서-클러스터 쌍으로 확장하여 처리를 간단하게 합니다.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # 확장된 목록에서 새 데이터프레임을 생성합니다.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # 처리를 위해 고유한 클러스터 식별자를 검색합니다.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # 요약\n",
    "    template = \"\"\"여기 LangChain 표현 언어 문서의 하위 집합이 있습니다.\n",
    "    \n",
    "    LangChain 표현 언어는 LangChain에서 체인을 구성하는 방법을 제공합니다.\n",
    "    \n",
    "    제공된 문서의 자세한 요약을 제공하십시오.\n",
    "    \n",
    "    문서:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 각 클러스터 내의 텍스트를 요약을 위해 포맷팅합니다.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # 요약, 해당 클러스터 및 레벨을 저장할 데이터프레임을 생성합니다.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95191d59",
   "metadata": {},
   "source": [
    "텍스트 데이터를 재귀적으로 임베딩, 클러스터링 및 요약하는 과정을 구현한 함수입니다.\n",
    "\n",
    "- 주어진 텍스트 리스트를 임베딩, 클러스터링 및 요약하여 각 단계별로 결과를 저장합니다.\n",
    "- 함수는 최대 지정된 재귀 레벨까지 실행되거나, 유일한 클러스터의 수가 1이 될 때까지 반복됩니다.\n",
    "- 각 재귀 단계에서는 현재 레벨의 클러스터링 결과와 요약 결과를 데이터프레임 형태로 반환하고, 이를 결과 딕셔너리에 저장합니다.\n",
    "- 만약 현재 레벨이 최대 재귀 레벨보다 작고, 유일한 클러스터의 수가 1보다 크다면, 현재 레벨의 요약 결과를 다음 레벨의 입력 텍스트로 사용하여 재귀적으로 함수를 호출합니다.\n",
    "- 최종적으로 각 레벨별 클러스터 데이터프레임과 요약 데이터프레임을 포함하는 딕셔너리를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c417dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    지정된 레벨까지 또는 고유 클러스터의 수가 1이 될 때까지 텍스트를 재귀적으로 임베딩, 클러스터링, 요약하여\n",
    "    각 레벨에서의 결과를 저장합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리할 텍스트들.\n",
    "    - level: int, 현재 재귀 레벨 (1에서 시작).\n",
    "    - n_levels: int, 재귀의 최대 깊이.\n",
    "\n",
    "    반환값:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], 재귀 레벨을 키로 하고 해당 레벨에서의 클러스터 DataFrame과 요약 DataFrame을 포함하는 튜플을 값으로 하는 사전.\n",
    "    \"\"\"\n",
    "    results = {}  # 각 레벨에서의 결과를 저장할 사전\n",
    "\n",
    "    # 현재 레벨에 대해 임베딩, 클러스터링, 요약 수행\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # 현재 레벨의 결과 저장\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # 추가 재귀가 가능하고 의미가 있는지 결정\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # 다음 레벨의 재귀 입력 텍스트로 요약 사용\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # 다음 레벨의 결과를 현재 결과 사전에 병합\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de5a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문서의 개수\n",
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e429ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n",
      "LangChain Expression Language (LCEL)는 LangChain에서 새로운 Runnable을 기존의 Runnable에서 구성하는 방법을 선언적으로 제공합니다. 이는 무엇이 일어나야 하는지를 설명하고, 어떻게 일어나야 하는지보다는 LangChain이 체인의 실행 시간을 최적화할 수 있게 합니다. LCEL을 사용하여 생성된 Runnable을 \"체인\"이라고 종종 부릅니다. 중요한 점은 \"체인\"이 Runnable을 구현하며, 전체 Runnable 인터페이스를 구현한다는 것입니다.\n",
      "\n",
      "LCEL의 주요 이점은 다음과 같습니다:\n",
      "\n",
      "- 최적화된 병렬 실행: RunnableParallel을 사용하여 Runnable을 병렬로 실행하거나, Runnable Batch API를 사용하여 주어진 체인을 통해 여러 입력을 병렬로 실행합니다. 병렬 실행은 처리를 순차적이 아닌 병렬로 수행할 수 있기 때문에 대기 시간을 크게 줄일 수 있습니다.\n",
      "- 보장된 비동기 지원: LCEL로 구축된 모든 체인은 Runnable Async API를 사용하여 비동기적으로 실행할 수 있습니다. 이는 대량의 요청을 동시에 처리하고자 하는 서버 환경에서 체인을 실행할 때 유용할 수 있습니다.\n",
      "- 스트리밍 간소화: LCEL 체인은 스트리밍될 수 있으며, 체인이 실행됨에 따라 점진적으로 출력을 허용합니다. LangChain은 첫 번째 토큰의 시간까지의 시간(챗 모델 또는 llm에서 첫 번째 출력 덩어리가 나올 때까지 걸리는 시간)을 최소화하기 위해 출력의 스트리밍을 최적화할 수 있습니다.\n",
      "\n",
      "LCEL은 오케스트레이션 솔루션으로, LangChain이 체인의 실행 시간을 최적화된 방식으로 처리할 수 있게 합니다. 복잡한 상태 관리, 분기, 순환 또는 여러 에이전트가 필요한 애플리케이션의 경우, LangGraph를 활용하는 것이 좋습니다. LangGraph에서는 애플리케이션의 흐름을 지정하는 그래프를 정의합니다. 이를 통해 사용자는 LCEL이 필요할 때 개별 노드 내에서 LCEL을 계속 사용하면서 복잡한 오케스트레이션 로직을 더 읽기 쉽고 유지 관리하기 쉬운 방식으로 정의할 수 있습니다.\n",
      "\n",
      "LCEL 체인은 기존 Runnable을 함께 구성하여 구축됩니다. 주요 구성 원시 데이터는 RunnableSequence와 RunnableParallel입니다. RunnableSequence는 여러 runnable을 순차적으로 \"연결\"하여, 하나의 runnable의 출력이 다음 runnable의 입력으로 사용되도록 합니다. 반면에 RunnableParallel은 동일한 입력을 각각에 제공하여 여러 runnable을 동시에 실행할 수 있게 합니다.\n",
      "\n",
      "LCEL은 타입 강제 변환을 자동으로 적용하여 체인을 더 쉽게 구성할 수 있게 합니다. 예를 들어, 함수는 RunnableLambda로 자동 변환되고, 사전은 RunnableParallel로 자동 변환됩니다. 이러한 강제 변환을 이해하지 못하더라도, RunnableSequence와 RunnableParallel 클래스를 직접 사용할 수 있습니다. 이렇게 하면 코드가 더 장황해지지만, 더 명시적이 됩니다.\n",
      "\n",
      "LCEL은 LLMChain과 ConversationalRetrievalChain과 같은 기존의 하위 클래스 체인에 대한 일관된 동작과 사용자 정의를 제공하려고 합니다. 많은 이러한 기존 체인은 프롬프트와 같은 중요한 세부 정보를 숨기며, 다양한 모델이 등장함에 따라 사용자 정의가 점점 더 중요해지고 있습니다. 현재 이러한 기존 체인을 사용하고 있다면, 마이그레이션 방법에 대한 안내를 참조하십시오."
     ]
    }
   ],
   "source": [
    "# 트리 구축\n",
    "leaf_texts = docs_texts  # 문서 텍스트를 리프 텍스트로 설정\n",
    "results = recursive_embed_cluster_summarize(\n",
    "    leaf_texts, level=1, n_levels=3\n",
    ")  # 재귀적으로 임베딩, 클러스터링 및 요약을 수행하여 결과를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314fe08",
   "metadata": {},
   "source": [
    "논문에서는 `collapsed tree retrieval`이 최고의 성능을 보고하고 있습니다.\n",
    "\n",
    "이는 트리 구조를 단일 계층으로 평탄화한 다음, 모든 노드에 대해 동시에 k-최근접 이웃(kNN) 검색을 적용하는 과정을 포함합니다.\n",
    "\n",
    "아래에서 이 과정을 간단히 수행합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af418d79",
   "metadata": {},
   "source": [
    "`Chroma` 벡터 저장소를 사용하여 텍스트 데이터의 벡터화 및 검색 가능한 저장소를 구축하는 과정을 설명합니다.\n",
    "\n",
    "- 초기에 `leaf_texts`에 저장된 텍스트 데이터를 `all_texts` 변수에 복사합니다.\n",
    "- 결과 데이터(`results`)를 순회하며 각 레벨에서 요약된 텍스트를 추출하고, 이를 `all_texts`에 추가합니다.\n",
    "  - 각 레벨의 `DataFrame`에서 `summaries` 컬럼의 값을 리스트로 변환하여 추출합니다.\n",
    "  - 추출된 요약문을 `all_texts`에 추가합니다.\n",
    "- 모든 텍스트 데이터(`all_texts`)를 사용하여 `Chroma` 벡터 저장소를 구축합니다.\n",
    "  - `Chroma.from_texts` 함수를 호출하여 텍스트 데이터를 벡터화하고, 벡터 저장소를 생성합니다.\n",
    "  - 생성된 벡터 저장소를 검색 가능하게 만들기 위해 `.as_retriever()` 메소드를 사용하여 검색기(retriever)를 초기화합니다.\n",
    "\n",
    "이 과정을 통해, 다양한 레벨의 요약문을 포함한 텍스트 데이터를 벡터화하고, 이를 기반으로 검색 가능한 `Chroma` 벡터 저장소를 구축합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd18b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# leaf_texts를 복사하여 all_texts를 초기화합니다.\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# 각 레벨의 요약을 추출하여 all_texts에 추가하기 위해 결과를 순회합니다.\n",
    "for level in sorted(results.keys()):\n",
    "    # 현재 레벨의 DataFrame에서 요약을 추출합니다.\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # 현재 레벨의 요약을 all_texts에 추가합니다.\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# 이제 all_texts를 사용하여 FAISS vectorstore를 구축합니다.\n",
    "vectorstore = FAISS.from_texts(texts=all_texts, embedding=embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eea66d",
   "metadata": {},
   "source": [
    "DB 를 로컬에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15f67a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DB_INDEX = \"RAPTOR\"\n",
    "\n",
    "# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\n",
    "if os.path.exists(DB_INDEX):\n",
    "    local_index = FAISS.load_local(DB_INDEX, embd)\n",
    "    local_index.merge_from(vectorstore)\n",
    "    local_index.save_local(DB_INDEX)\n",
    "else:\n",
    "    vectorstore.save_local(folder_path=DB_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "398b4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da0f7e",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation(RAG) 체인을 정의하고 특정 코드 예제를 요청하는 방법을 구현합니다.\n",
    "\n",
    "- `hub.pull`을 사용하여 RAG 프롬프트를 불러옵니다.\n",
    "- 문서 포맷팅을 위한 `format_docs` 함수를 정의합니다. 이 함수는 문서의 페이지 내용을 연결하여 반환합니다.\n",
    "- RAG 체인을 구성합니다. 이 체인은 검색기(`retriever`)로부터 문맥을 가져오고, `format_docs` 함수로 포맷팅한 후, 질문을 처리합니다.\n",
    "- `RunnablePassthrough()`를 사용하여 질문을 그대로 전달합니다.\n",
    "- 체인은 프롬프트, 모델, 그리고 `StrOutputParser()`를 통해 최종 출력을 문자열로 파싱합니다.\n",
    "- `rag_chain.invoke` 메소드를 사용하여 \"How to define a RAG chain? Give me a specific code example.\"라는 질문을 처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9c26dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 문서 포스트 프로세싱\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 문서의 페이지 내용을 이어붙여 반환합니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c647f82",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/178afde0-8dcc-472f-8c47-233fe81cbbad/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0efdda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Expression Language (LCEL)는 LangChain에서 새로운 Runnable을 기존의 Runnable에서 구성하는 방법을 선언적으로 제공하는 오케스트레이션 솔루션입니다. LCEL을 사용하여 생성된 Runnable, 즉 \"체인\"을 통해 병렬 실행, 비동기 지원, 스트리밍 간소화 등의 이점을 제공하며, 복잡한 상태 관리나 여러 에이전트가 필요한 애플리케이션의 경우 LangGraph를 활용하는 것이 좋습니다. LCEL은 타입 강제 변환을 자동으로 적용하여 체인을 더 쉽게 구성할 수 있게 하며, 사용자 정의가 중요해지는 다양한 모델에 대한 일관된 동작과 사용자 정의를 제공합니다."
     ]
    }
   ],
   "source": [
    "# 추상적인 질문 실행\n",
    "_ = rag_chain.invoke(\"전체 문서의 핵심 주제에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b34ee",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/1d72738b-f378-4676-9961-dd12fe424918/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e8193fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the provided context does not contain any specific example code or instructions on how to use PydanticOutputParser with LangChain Expression Language (LCEL) or any other context. The context primarily discusses the benefits and concepts of LCEL in LangChain, without specific examples or code snippets related to PydanticOutputParser."
     ]
    }
   ],
   "source": [
    "# Low Level 질문 실행\n",
    "_ = rag_chain.invoke(\"PydanticOutputParser 을 활용한 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e4e23",
   "metadata": {},
   "source": [
    "[LangSmith 링크](https://smith.langchain.com/public/bd725efb-d854-4d0e-b34b-52748dddcf4b/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52666307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송하지만 제공된 문맥에서는 \"self-querying\" 방법에 대한 구체적인 예시 코드를 직접 제공하지 않습니다. \"self-querying\"에 대한 설명이나 예시 코드를 찾기 위해서는 LangChain의 공식 문서나 API 참조 가이드를 확인하는 것이 좋습니다. LCEL을 사용한 예시 코드 작성은 LangChain의 문서에서 더 자세한 정보와 가이드를 제공받을 수 있을 것입니다."
     ]
    }
   ],
   "source": [
    "# Low Level 질문 실행\n",
    "_ = rag_chain.invoke(\"self-querying 방법과 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4892f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a32e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d5112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4baec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
