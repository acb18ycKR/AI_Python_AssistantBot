import os
import numpy as np
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sklearn.mixture import GaussianMixture
import umap
from langchain_community.document_loaders import PDFPlumberLoader

RANDOM_SEED = 42
DB_INDEX = "RAPTOR_DB"

# Embedding Initialization
embd = OpenAIEmbeddings(model="text-embedding-ada-002")

# Chat Model Initialization
model = ChatOpenAI(model="gpt-4o", temperature=0)

# PDF ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• 
def load_and_split_pdf(pdf_path, chunk_size=1100, chunk_overlap=100):
    """
    PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
    """
    try:
        loader = PDFPlumberLoader(pdf_path)
        docs = loader.load()
        print(f"âœ… PDFì—ì„œ ë¡œë“œëœ ë¬¸ì„œ íƒ€ì…: {type(docs)}")
        print(f"âœ… PDFì—ì„œ ë¡œë“œëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
        
        for i, doc in enumerate(docs[:5]):  # ì²˜ìŒ 5ê°œ ë¬¸ì„œ íƒ€ì…ê³¼ ë‚´ìš©ì„ ì¶œë ¥
            print(f"ğŸ” ë¬¸ì„œ {i} íƒ€ì…: {type(doc)}")
            print(f"ğŸ” ë¬¸ì„œ {i} ë‚´ìš©: {doc}")
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        split_docs = text_splitter.split_documents(docs)
        print(f"âœ… ë¶„í• ëœ ë¬¸ì„œ ê°œìˆ˜: {len(split_docs)}")
        
        for i, split_doc in enumerate(split_docs[:5]):  # ë¶„í• ëœ ë¬¸ì„œ ì¤‘ 5ê°œì˜ íƒ€ì…ê³¼ ë‚´ìš©ì„ ì¶œë ¥
            print(f"ğŸ” ë¶„í• ëœ ë¬¸ì„œ {i} íƒ€ì…: {type(split_doc)}")
            print(f"ğŸ” ë¶„í• ëœ ë¬¸ì„œ {i} ë‚´ìš©: {split_doc}")
            
        return split_docs
    except Exception as e:
        raise ValueError(f"PDF ë¡œë“œ ë° ë¶„í•  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
# Global Clustering
def global_cluster_embeddings(embeddings, dim, n_neighbors=None, metric="cosine"):
    if n_neighbors is None:
        n_neighbors = int((len(embeddings) - 1) ** 0.5)
    return umap.UMAP(n_neighbors=n_neighbors, n_components=dim, metric=metric).fit_transform(embeddings)

# Perform Clustering
def perform_clustering(embeddings, dim, threshold):
    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)
    gm = GaussianMixture(n_components=5, random_state=RANDOM_SEED).fit(reduced_embeddings_global)
    probs = gm.predict_proba(reduced_embeddings_global)
    labels = [np.where(prob > threshold)[0].tolist() for prob in probs]
    return labels

# Embedding Texts
def embed_texts(texts):
    embeddings = embd.embed_documents(texts)
    return np.array(embeddings)

# Create Vectorstore
def create_vectorstore(documents):
    """
    Vectorstoreë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        vectorstore = FAISS.from_documents(documents=documents, embedding=embd)
        if os.path.exists(DB_INDEX):
            # Pickle ì—­ì§ë ¬í™”ë¥¼ í—ˆìš©
            local_index = FAISS.load_local(DB_INDEX, embd, allow_dangerous_deserialization=True)
            local_index.merge_from(vectorstore)
            local_index.save_local(DB_INDEX)
        else:
            vectorstore.save_local(DB_INDEX)
        return vectorstore.as_retriever()
    except Exception as e:
        raise ValueError(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# RAG Chain Initialization
def create_raptor_rag_chain(vectorstore):
    prompt = ChatPromptTemplate.from_template(
        """ë„ˆëŠ” íŒŒì´ì¬ ìš©ì–´ ì‚¬ì „ê³¼ í€´ì¦ˆ í’€ê¸° ê¸°ëŠ¥ì´ ìˆëŠ” AI í•™ìŠµ ë¹„ì„œ ì±—ë´‡ì´ì•¼. """
    )
    return {
        "context": vectorstore | (lambda docs: "\n\n".join([doc.page_content for doc in docs])),
        "question": RunnablePassthrough()
    } | prompt | model | StrOutputParser()

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
def initialize_raptor_rag_system(pdf_path):
    try:
        # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
        documents = load_and_split_pdf(pdf_path)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í™•ì¸
        texts = [doc.page_content for doc in documents]
        print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(texts)} ê°œ ë¬¸ì„œ")
        print(f"ğŸ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {texts[:5]}")  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì¤‘ 5ê°œ ì¶œë ¥

        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        retriever = create_vectorstore(documents)  # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
        print("âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
        
        # RAG ì²´ì¸ ìƒì„±
        return create_raptor_rag_chain(retriever)
    except Exception as e:
        raise ValueError(f"RAPTOR RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
def generate_raptor_rag_answer(question, rag_chain):
    try:
        return rag_chain.invoke(question)
    except Exception as e:
        return f"Error generating answer: {str(e)}" 