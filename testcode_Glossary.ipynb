{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 rag 성능평가 - gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 초기화\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "def load_and_split_pdf(pdf_path, chunk_size=1100, chunk_overlap=100):\n",
    "    try:\n",
    "        loader = PDFPlumberLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        return text_splitter.split_documents(docs)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"PDF 로드 및 분할 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "def create_embeddings():\n",
    "    return OpenAIEmbeddings()\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "def create_vector_store(documents, embeddings):\n",
    "    try:\n",
    "        return FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"벡터 저장소 생성 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG 체인 생성\n",
    "def create_rag_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"너는 용어 사전에 대한 전문가야. 다음 검색된 context를 사용해서 질문에 맞는 용어를 정의해줘.\n",
    "        답을 모르면, '알 수 없습니다.'라고 대답해.\n",
    "\n",
    "        # Context : {context}\n",
    "        # Question : {question}\n",
    "        # Answer :\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "    return (\n",
    "        {'context': retriever, 'question': RunnablePassthrough()}  \n",
    "        | prompt  \n",
    "        | llm  \n",
    "        | StrOutputParser()  \n",
    "    )\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "def generate_rag_answer(question, rag_chain):\n",
    "    try:\n",
    "        return rag_chain.invoke(question)\n",
    "    except Exception as e:\n",
    "        return f\"오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# PDF 문서 기반 RAG 시스템 초기화\n",
    "def initialize_rag_system(pdf_path):\n",
    "    try:\n",
    "        documents = load_and_split_pdf(pdf_path)\n",
    "        embeddings = create_embeddings()\n",
    "        vectorstore = create_vector_store(documents, embeddings)\n",
    "        return create_rag_chain(vectorstore)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"RAG 시스템 초기화 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # PDF 파일 경로\n",
    "    pdf_path = \"C:\\AI_Python_AssistantBot\\data\\converted_data_with_metadata.pdf\"\n",
    "    \n",
    "    try:\n",
    "        # RAG 시스템 초기화\n",
    "        rag_chain = initialize_rag_system(pdf_path)\n",
    "        \n",
    "        print(\"✅ RAG 시스템이 성공적으로 초기화되었습니다.\")\n",
    "\n",
    "        # 테스트 질문 입력\n",
    "        question = \"파이썬의 for문의 정의를 알려줘\"\n",
    "        print(f\"질문: {question}\")\n",
    "        \n",
    "        # 답변 생성\n",
    "        answer = generate_rag_answer(question, rag_chain)\n",
    "        print(f\"답변: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG 성능 테스트 함수\n",
    "def ragas_test(question, answer, retrieved_context):\n",
    "    \"\"\"\n",
    "    질문, 답변, 검색된 컨텍스트를 기반으로 성능 평가를 실행합니다.\n",
    "    Args:\n",
    "        question (str): 질문\n",
    "        answer (str): 모델의 답변\n",
    "        retrieved_context (list): 검색된 컨텍스트\n",
    "    Returns:\n",
    "        dict: 평가 결과\n",
    "    \"\"\"\n",
    "    # 데이터셋 생성\n",
    "    dataset = [{\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_context\": \"\\n\\n\".join(retrieved_context)\n",
    "    }]\n",
    "\n",
    "    # 평가 지표 정의\n",
    "    def answer_relevancy(dataset):\n",
    "        relevancies = [1 if d[\"answer\"] in d[\"retrieved_context\"] else 0 for d in dataset]\n",
    "        return sum(relevancies) / len(relevancies)\n",
    "\n",
    "    def faithfulness(dataset):\n",
    "        faithfulness_scores = [1 if d[\"answer\"] == d[\"retrieved_context\"] else 0 for d in dataset]\n",
    "        return sum(faithfulness_scores) / len(faithfulness_scores)\n",
    "\n",
    "    def context_recall(dataset):\n",
    "        recalls = [1 if d[\"answer\"] in d[\"retrieved_context\"] else 0 for d in dataset]\n",
    "        return sum(recalls) / len(recalls)\n",
    "\n",
    "    def context_precision(dataset):\n",
    "        precisions = [1 if d[\"answer\"] in d[\"retrieved_context\"] else 0 for d in dataset]\n",
    "        return sum(precisions) / len(precisions)\n",
    "\n",
    "    # 평가 실행\n",
    "    metrics = [\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_recall,\n",
    "        context_precision\n",
    "    ]\n",
    "    results = {metric.__name__: metric(dataset) for metric in metrics}\n",
    "    return results\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 예시 데이터\n",
    "    question = \"파이썬의 for문의 정의를 알려줘\"\n",
    "    answer = \"for문은 반복문으로, 리스트나 튜플 등의 항목을 반복적으로 실행할 수 있게 한다.\"\n",
    "    retrieved_context = [\n",
    "        \"for문은 반복문으로, 리스트나 튜플 등의 항목을 반복적으로 실행할 수 있게 한다.\",\n",
    "        \"파이썬의 반복문에는 for문과 while문이 있다.\"\n",
    "    ]\n",
    "    \n",
    "    # RAG 성능 평가 실행\n",
    "    result = ragas_test(question, answer, retrieved_context)\n",
    "    print(\"RAG 성능 평가 결과:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 rag 성능평가 - gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 초기화\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "def load_and_split_pdf(pdf_path, chunk_size=1100, chunk_overlap=100):\n",
    "    try:\n",
    "        loader = PDFPlumberLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        return text_splitter.split_documents(docs)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"PDF 로드 및 분할 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "def create_embeddings():\n",
    "    return OpenAIEmbeddings()\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "def create_vector_store(documents, embeddings):\n",
    "    try:\n",
    "        return FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"벡터 저장소 생성 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG 체인 생성\n",
    "def create_rag_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"너는 용어 사전에 대한 전문가야. 다음 검색된 context를 사용해서 질문에 맞는 용어를 정의해줘.\n",
    "        답을 모르면, '알 수 없습니다.'라고 대답해.\n",
    "\n",
    "        # Context : {context}\n",
    "        # Question : {question}\n",
    "        # Answer :\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "    return (\n",
    "        {'context': retriever, 'question': RunnablePassthrough()}  \n",
    "        | prompt  \n",
    "        | llm  \n",
    "        | StrOutputParser()  \n",
    "    )\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "def generate_rag_answer(question, rag_chain):\n",
    "    try:\n",
    "        return rag_chain.invoke(question)\n",
    "    except Exception as e:\n",
    "        return f\"오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# PDF 문서 기반 RAG 시스템 초기화\n",
    "def initialize_rag_system(pdf_path):\n",
    "    try:\n",
    "        documents = load_and_split_pdf(pdf_path)\n",
    "        embeddings = create_embeddings()\n",
    "        vectorstore = create_vector_store(documents, embeddings)\n",
    "        return create_rag_chain(vectorstore)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"RAG 시스템 초기화 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # PDF 파일 경로\n",
    "    pdf_path = \"C:\\AI_Python_AssistantBot\\data\\converted_data_with_metadata.pdf\"\n",
    "    \n",
    "    try:\n",
    "        # RAG 시스템 초기화\n",
    "        rag_chain = initialize_rag_system(pdf_path)\n",
    "        \n",
    "        print(\"✅ RAG 시스템이 성공적으로 초기화되었습니다.\")\n",
    "\n",
    "        # 테스트 질문 입력\n",
    "        question = \"파이썬의 for문의 정의를 알려줘\"\n",
    "        print(f\"질문: {question}\")\n",
    "        \n",
    "        # 답변 생성\n",
    "        answer = generate_rag_answer(question, rag_chain)\n",
    "        print(f\"답변: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 중 오류가 발생했습니다: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 rag 성능평가 -  gpt-4-turbo-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 초기화\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "def load_and_split_pdf(pdf_path, chunk_size=1100, chunk_overlap=100):\n",
    "    try:\n",
    "        loader = PDFPlumberLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        return text_splitter.split_documents(docs)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"PDF 로드 및 분할 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "def create_embeddings():\n",
    "    return OpenAIEmbeddings()\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "def create_vector_store(documents, embeddings):\n",
    "    try:\n",
    "        return FAISS.from_documents(documents=documents, embedding=embeddings)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"벡터 저장소 생성 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG 체인 생성\n",
    "def create_rag_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"너는 용어 사전에 대한 전문가야. 다음 검색된 context를 사용해서 질문에 맞는 용어를 정의해줘.\n",
    "        답을 모르면, '알 수 없습니다.'라고 대답해.\n",
    "\n",
    "        # Context : {context}\n",
    "        # Question : {question}\n",
    "        # Answer :\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "    return (\n",
    "        {'context': retriever, 'question': RunnablePassthrough()}  \n",
    "        | prompt  \n",
    "        | llm  \n",
    "        | StrOutputParser()  \n",
    "    )\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "def generate_rag_answer(question, rag_chain):\n",
    "    try:\n",
    "        return rag_chain.invoke(question)\n",
    "    except Exception as e:\n",
    "        return f\"오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# PDF 문서 기반 RAG 시스템 초기화\n",
    "def initialize_rag_system(pdf_path):\n",
    "    try:\n",
    "        documents = load_and_split_pdf(pdf_path)\n",
    "        embeddings = create_embeddings()\n",
    "        vectorstore = create_vector_store(documents, embeddings)\n",
    "        return create_rag_chain(vectorstore)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"RAG 시스템 초기화 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # PDF 파일 경로\n",
    "    pdf_path = \"C:\\AI_Python_AssistantBot\\data\\converted_data_with_metadata.pdf\"\n",
    "    \n",
    "    try:\n",
    "        # RAG 시스템 초기화\n",
    "        rag_chain = initialize_rag_system(pdf_path)\n",
    "        \n",
    "        print(\"✅ RAG 시스템이 성공적으로 초기화되었습니다.\")\n",
    "\n",
    "        # 테스트 질문 입력\n",
    "        question = \"파이썬의 for문의 정의를 알려줘\"\n",
    "        print(f\"질문: {question}\")\n",
    "        \n",
    "        # 답변 생성\n",
    "        answer = generate_rag_answer(question, rag_chain)\n",
    "        print(f\"답변: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 중 오류가 발생했습니다: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4o - RAPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import umap\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "DB_INDEX = \"RAPTOR_DB\"\n",
    "\n",
    "# Embedding Initialization\n",
    "embd = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Chat Model Initialization\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# PDF 로드 및 텍스트 분할\n",
    "# PDF 로드 및 텍스트 분할\n",
    "def load_and_split_pdf(pdf_path, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    PDF 문서를 로드하고 텍스트를 분할합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = PDFPlumberLoader(pdf_path)\n",
    "        docs = loader.load()\n",
    "        print(f\"✅ PDF에서 로드된 문서 타입: {type(docs)}\")\n",
    "        print(f\"✅ PDF에서 로드된 문서 개수: {len(docs)}\")\n",
    "        \n",
    "        for i, doc in enumerate(docs[:5]):  # 처음 5개 문서 타입과 내용을 출력\n",
    "            print(f\"🔍 문서 {i} 타입: {type(doc)}\")\n",
    "            print(f\"🔍 문서 {i} 내용: {doc}\")\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        split_docs = text_splitter.split_documents(docs)\n",
    "        print(f\"✅ 분할된 문서 개수: {len(split_docs)}\")\n",
    "        \n",
    "        for i, split_doc in enumerate(split_docs[:5]):  # 분할된 문서 중 5개의 타입과 내용을 출력\n",
    "            print(f\"🔍 분할된 문서 {i} 타입: {type(split_doc)}\")\n",
    "            print(f\"🔍 분할된 문서 {i} 내용: {split_doc}\")\n",
    "            \n",
    "        return split_docs\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"PDF 로드 및 분할 중 오류가 발생했습니다: {str(e)}\")\n",
    "    \n",
    "# Global Clustering\n",
    "def global_cluster_embeddings(embeddings, dim, n_neighbors=None, metric=\"cosine\"):\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(n_neighbors=n_neighbors, n_components=dim, metric=metric).fit_transform(embeddings)\n",
    "\n",
    "# Perform Clustering\n",
    "def perform_clustering(embeddings, dim, threshold):\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    gm = GaussianMixture(n_components=5, random_state=RANDOM_SEED).fit(reduced_embeddings_global)\n",
    "    probs = gm.predict_proba(reduced_embeddings_global)\n",
    "    labels = [np.where(prob > threshold)[0].tolist() for prob in probs]\n",
    "    return labels\n",
    "\n",
    "# Embedding Texts\n",
    "def embed_texts(texts):\n",
    "    embeddings = embd.embed_documents(texts)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Create Vectorstore\n",
    "def create_vectorstore(documents):\n",
    "    \"\"\"\n",
    "    Vectorstore를 생성합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vectorstore = FAISS.from_documents(documents=documents, embedding=embd)\n",
    "        if os.path.exists(DB_INDEX):\n",
    "            local_index = FAISS.load_local(DB_INDEX, embd)\n",
    "            local_index.merge_from(vectorstore)\n",
    "            local_index.save_local(DB_INDEX)\n",
    "        else:\n",
    "            vectorstore.save_local(DB_INDEX)\n",
    "        return vectorstore.as_retriever()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"벡터스토어 생성 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG Chain Initialization\n",
    "def create_raptor_rag_chain(vectorstore):\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an expert at summarizing complex information. Use the given context to answer the question.\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        Answer:\"\"\"\n",
    "    )\n",
    "    return {\n",
    "        \"context\": vectorstore | (lambda docs: \"\\n\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    } | prompt | model | StrOutputParser()\n",
    "\n",
    "# RAG 시스템 초기화\n",
    "\n",
    "def initialize_raptor_rag_system(pdf_path):\n",
    "    try:\n",
    "        # 문서 로드 및 분할\n",
    "        documents = load_and_split_pdf(pdf_path)\n",
    "        \n",
    "        # 텍스트 추출 및 확인\n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        print(f\"✅ 텍스트 추출 완료: {len(texts)} 개 문서\")\n",
    "        print(f\"🔍 추출된 텍스트 샘플: {texts[:5]}\")  # 추출된 텍스트 중 5개 출력\n",
    "\n",
    "        # 벡터스토어 생성\n",
    "        retriever = create_vectorstore(documents)  # 문서 리스트 전달\n",
    "        print(\"✅ 벡터스토어 생성 완료\")\n",
    "        \n",
    "        # RAG 체인 생성\n",
    "        return create_raptor_rag_chain(retriever)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"RAPTOR RAG 시스템 초기화 중 오류가 발생했습니다: {str(e)}\")\n",
    "\n",
    "# RAG 시스템 초기화\n",
    "def generate_raptor_rag_answer(question, rag_chain):\n",
    "    try:\n",
    "        return rag_chain.invoke(question)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating answer: {str(e)}\" \n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # PDF 파일 경로\n",
    "    pdf_path = r\"C:\\Users\\RMARKET\\workspace\\assistntbot\\AI_Python_AssistantBot\\data\\converted_data_test_with_metadata.pdf\"\n",
    "    \n",
    "    try:\n",
    "        # RAG 시스템 초기화\n",
    "        rag_chain = initialize_raptor_rag_system(pdf_path)\n",
    "        \n",
    "        print(\"✅ RAG 시스템이 성공적으로 초기화되었습니다.\")\n",
    "\n",
    "        # 테스트 질문 입력\n",
    "        question = \"용어사전 함수\"\n",
    "        print(f\"질문: {question}\")\n",
    "        \n",
    "        # 답변 생성\n",
    "        answer = generate_rag_answer(question, rag_chain)\n",
    "        print(f\"답변: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 중 오류가 발생했습니다: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
